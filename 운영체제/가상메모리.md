## 17. 가상 메모리란 무엇인가요?

> 가상 메모리 시스템에서, 프로그램은 자신이 사용하는 메모리가 실제 물리 메모리와 동일하다고 가정합니다. 즉, 프로그램은 자신이 전체 메모리를 독점하고 있고, 연속적인 메모리 공간을 가지고 있다고 가정합니다. 이는 각 프로그램이 메모리를 보다 쉽게 관리할 수 있게 해줍니다.

가상 메모리(virtual memory)는 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다. 이 기법을 통해 사용자 프로그램이 물리적인 메모리 (physical memory)보다 커져도 된다. 즉, **물리 메모리로 부터 프로그래머 관점의 논리 메모리를 분리**하는 기법이라고 할 수 있다.

가상 메모리는 **페이지나 세그먼트**라는 단위로 물리적 메모리에 올라간다. 이 단위는 실제 필요한 시점에 메모리에 로드되고, 메모리가 부족한 경우 이들 중 사용하지 않는 페이지나 세그먼트를 보조 기억 장치 (예 : 하드디스크) 로 옮겨서 물리 메모리 공간을 확보한다. 이를 통해 각 프로그램에 더 적은 메모리를 차지 하므로 효율적인 메모리 사용이 가능하며, 더 많은 프로세스를 동시에 수행할 수 있다.

### 가상 메모리가 가능한 이유가 무엇일까요?

실제 프로그램들을 살펴보면 많은 경우에 프로그램 전체가 한꺼번에 메모리에 늘 올라와있어야 하는 것은 아니다.

- 프로그램에는 잘 발생하지 않는 오류 상황을 처리하는 코드가 존재
- 배열, 리스트, 테이블은 필요 이상으로 많은 공간을 점유함 (실제로 사용하는 부분보다 많이 선언할 수 있음)
- 프로그램 내에 아주 드물게 사용하는 옵션이나 기능 (전체 프로그램이 필요해도 모든 부분이 모두 **동시**에 요구되지 않음)

- **요구 페이징**
  가상 메모리 시스템에서는 일반적으로 **요구 페이징** 기법을 사용하여 프로그램 실행 중 **필요할 때만** 페이지가 적재되도록 한다. 따라서 프로세스가 실행되는 동안 일부 페이지는 메모리에 있고 일부는 보조 저장 장치에 있다.
  - 비트를 둬서 **valid 하다고 하면 해당 페이지가 메모리에 있다**는 의미이고, **invalid 하다고 설정되면 메모리에 올라와있지 않다**는 의미이다.
  - invalid 의 경우, 두 가지 상황이 있다. **해당 가상 페이지에 대한 참조가 주소 공간을 벗어나는 경우**와 **가상 페이지가 유효하지만 아직 메모리에 적재되지 않은 경우**이다.

### Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.

- **Page Fault Trap** : 프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 할 때, 페이지 테이블 항목이 무효로 설정되어 있으므로 페이지 폴트 트랩이 발생함.
  ![[Pasted image 20230518173304.png]]
- **페이지 폴트를 처리하는 과정**

1. **페이지 테이블**(메인 메모리에 존재)을 검사해서 그 메모리 참조가 유효 / 무효인지를 알아낸다.
2. 무효한 테이블인 경우 프로세스를 중단함. (유효한 참조인데 페이지가 아직 메모리에 올라오지 않았다면, 보조 저장 장치를 통해 페이지를 가져옴)
3. 가용 프레임(free frame, 즉 빈 공간을 말한다)을 찾는다. (빈 프레임이 없다면 운영체제가 페이지 교체 알고리즘 수행합니다.)
4. 보조저장장치에 새로이 할당된 프레임으로 해당 페이지를 읽어들이도록 요청한다.
5. 보조저장장치 읽기가 끝나면, 이 페이지가 이제는 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다. 이제 프로세스는 마치 그 페이지가 항상 메모리에 있었던 것 처럼 해당 페이지에 접근할 수 있다.

정리하면,

페이지 폴트는 메모리에 없는 페이지를 참조하려고 할 때 발생합니다. 먼저 페이지 테이블에서 해당 페이지에 대한 메모리 참조 정보를 찾습니다. 이 때 해당 가상 페이지에 대한 참조가 프로그램의 주소 공간을 벗어나는 경우에는 프로세스를 종료하고, 메모리에 올라오지 않는 상태라면 보조 저장 장치를 통해 페이지를 가져옵니다.
페이지를 메모리에 적재하기 위하여 메인 메모리에 빈 프레임을 찾습니다. 이 후, 보조저장장치를 읽어, 이 페이지를 메모리에 적재합니다.
이제 페이지가 메인 메모리로 올라왔으므로 페이지 테이블의 비트를 유효로 업데이트 합니다.
이 과정이 끝나면 본래 실행 중이던 프로세스에서 트랩에 이해 중단되었던 명령어를 다시 수행합니다.

### 페이지 크기에 대한 Trade-Off를 설명해 주세요.

- **메모리 공간 사용 효율성**
  - 페이지가 작으면 메모리 내부의 빈 공간을 줄일 수 있다. (내부 단편화, internal fragmentation을 줄일 수 있음)
  - 큰 페이지를 사용하는 경우, 빈공간이 많이 생길 수 있다.
- **페이지 테이블 크기**
  - 페이지가 클 수록 페이지의 갯수가 줄어들기 때문에 페이지 테이블의 크기가 작아진다. 이는 메모리와 CPU의 오버 헤드를 줄일 수 있다.

### 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?

페이지 크기가 크면 페이지 테이블에 있는 각 엔트리가 더 많은 메모리 영역을 커버하고, 대부분의 경우 비슷한 위치에 있는 메모리를 참조할 확률이 높기 때문에 (메모리 지역성) 페이지 폴트가 감소할 수 있다. (그러나 그렇다고 성능이 증가한다고 말하기는 힘들다. 왜냐하면 이 때, 페이지 폴트가 발생하면 오버헤드가 더 커질 수 있기 때문이다. 페이지 크기가 커질 수록 페이지 폴트 발생 시 디스크에서 메모리로 로드해야 하는 데이터 양이 증가한다)

## 18. 세그멘테이션과 페이징의 차이점은 무엇인가요?

- **세그멘테이션**
  **메모리를 동적으로, 필요한 만큼 분할**하는 방식. 프로세스의 **메모리 요구 사항에 따라 메모리를 다양한 크기의 세그먼트로 분할하여 관리**한다. 메모리의 효율적인 사용을 가능하게 하지만, 시간이 지남에 따라 메모리 공간 사이에 작은 빈 공간(hole)이 생겨날 수 있다.

- **페이징**
  **외부 단편화 문제를 해결하고, 사용 가능한 환경이 제한적이거나 비싼 압축 기법을 사용하는 대신 페이징 기법을 사용**한다. 이를 통해 메모리에 올라가 있는 프로세스의 물리 주소 공간이 연속적이지 않게 된다.
  **페이징은 주소 공간을 적절한 단위 크기로 쪼개서 이 단위 마다 물리 주소와 논리 주소를 매칭**시키는 것이다. **물리 주소 관점에서 이 단위를 프레임(Frame), 논리 주소 관점에서 이 단위를 페이지(Page)라고 한다.**

  페이징을 사용하면 반드시 물리적으로 인접한 주소 공간을 구할 필요가 없고, 인접한 논리 주소 공간을 물리적으로는 쪼갤 수 있으므로 모든 프레임을 가용할 수 있어 외부 단편화가 더 이상 발생하지 않는다. 단, 무조건 페이지 크기의 배수만큼만 할당이 이루어지므로, 페이지 크기 안에서 내부 단편화가 더 크게 발생할 수 있다.

- **세그멘테이션 기법과의 차이**
  - **메모리 분할 방식** : **세그멘테이션은 프로세스의 메모리 요구사항에 따라 가변 크기의 세그먼트로 메모리를 분할**한다. 반면에, 페이징은 메모리를 고정된 크기의 페이지로 분할한다.
  - **조각화 문제** : **세그멘테이션은 메모리 공간 사이에 작은 빈 공간들이 생기는 외부 조각화 문제가 발생**할 수 있다. 반면에 페이징은 각 페이지 내에서 메모리가 낭비되는 내부 조각화 문제를 가질 수 있다.
  - **메모리 관리 복잡성** : 페이징은 고정 크기의 페이지를 사용하기 때문에 메모리 관리가 상대적으로 간단하다. 반면에 세그멘테이션은 메모리를 가변 크기의 세그먼트로 관리하기 때문에 메모리 관리가 복잡할 수 있다.
  - **논리적 단위와 일치성** : 세그멘테이션은 프로그램의 논리적 구조와 일치하는 메모리 분할 방식을 제공한다.

### 페이지와 프레임의 차이에 대해 설명해 주세요.

> **페이징은 주소 공간을 적절한 단위 크기로 쪼개서 이 단위 마다 물리 주소와 논리 주소를 매칭**시키는 것이다. **물리 주소 관점에서 이 단위를 프레임(Frame), 논리 주소 관점에서 이 단위를 페이지(Page)라고 한다.**

### 내부 단편화와, 외부 단편화에 대해 설명해 주세요.

프로세스들이 메모리에 적재되고 제거되는 일이 반복되다보면, **메모리가 작은 조각들로 나누어져서 실제로 사용되는 메모리보다 총 사용가능한 메모리가 작게되는 현상.**

- **외부 단편화** : 연속적인 메모리 할당 방식에서 발생. 프로세스들이 메모리에 할당하고 해제되는 과정에서 메모리의 앞 뒤에 작은 빈 공간들이 생겨남. 이 공간들을 합치면 큰 메모리 공간이 될 수 있지만, 연속적이지 않으므로 큰 메모리 공간을 요구하는 프로세스에 해당 공간을 할당해줄 수 없다.
- **내부 단편화** : 프로세스가 사용하는 메모리 내부 공간에 포함된 남는 부분. 고정 크기 파티션 또는 페이지 처럼 블록 단위로 메모리를 할당할 때 발생함.

### 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.

이 작업은 MMU(Memory Management Unit)가 수행한다.
![[Pasted image 20230511145452.png]]

- 페이지 번호 : 특정 프레임과 매핑되는 번호
- 오프셋 : 참조하는 프레임 안에서의 위치

1. 페이지 번호 p를 추출하여 페이지 테이블의 인덱스로 사용한다.
2. 페이지 테이블에서 해당 프레임 번호 f를 추출한다.
3. 논리 주소의 페이지 번호 p를 프레임 번호 f로 바꾼다.

오프셋 d는 변하지 않기 때문에 대체되지 않으며, 프레임 번호와 오프셋을 통하여 물리 주소를 구성한다.

### 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?

- 주소 공간의 수정 가능 여부는 **해당 주소 공간의 권한 설정**에 따라 결정된다. 일반적으로 프로세스의 메모리 주소 공간은 여러 가지 영역으로 나누어져있으며, 이 영역은 서로 다른 권한을 가질 수 있다.
- 이러한 메모리의 주소공간과 권한 설정은 운영체제가 담당하며, 권한 설정은 페이지 테이블 등의 메모리 관리 자료구조에 저장되어 있다. 따라서 특정 주소 공간이 수정 가능한지 여부를 확인하기 위해서는 해당 주소가 속한 영역의 권한을 확인해야 한다.
- 대부분의 경우, 프로그램은 운영 체제가 제공하는 API를 통해 메모리를 할당받고, 해당 메모리 영역이 읽기/쓰기 가능하다고 가정한다. 따라서 **특정 주소 공간이 수정 가능 여부를 확인하려면 그 주소 공간에 쓰기 작업을 시도하거나, 운영 체제의 메모리 관리 API를 사용해 해당 주소의 권한을 확인**해야 한다.

### 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?

- 페이지의 크기를 나타내는데 필요한 비트 수를 계산할 때는 바이트 단위를 사용한다. 우선 페이의 크기를 나타내는데 사용하는 비트수는 log2(1024) = 10 bit 이다.
- 1KB = 1024 byte -> 페이지 주소를 나타내는데 필요한 비트 수는 log2(1024) = 10 bit 이다.
- 각 페이지에 대한 페이지 번호 (p) 를 나타내는 데 필요한 비트 수는 32 - 10 = 22 bit, 32 bit 주소 공간에서 10 비트를 사용하여 페이지의 크기를 나타내면 나머지 22 비트는 페이지 테이블의 인덱스를 나타내는데 사용한다. 이 인덱스의 크기는 가능한 페이지의 총 수를 결정한다.
- 그러므로, 페이지 테이블의 최대 크기는 2^22 개의 항목을 가질 수 있다.

## 19. TLB는 무엇인가요?

Transfer Look-Aside Buffer. 매우 빠른 associtative memory로 구성되고, key와 value의 두 부분으로 구성된다. TLB에 페이지를 찾아달라고 요청하면 캐시의 동작 방식과 같이 동시에 여러 개의 내부 키 (페이지 번호) 와 비교하여 그에 대응하는 프레임 번호를 알려준다.

### TLB를 쓰면 왜 빨라지나요?

페이지 테이블은 메인 메모리에 접근하는데, 메인 메모리는 접근하는데 시간이 오래걸리기 때문에 중간에 TLB를 두는데, TLB에서의 페이지 검색 속도는 해당 페이지를 동시에 여러 개의 내부 키와 비교함으로써 검색의 속도가 아주 빠르다.

### MMU가 무엇인가요?

컴퓨터 시스템에서 가상 메모리와 물리 메모리 사이의 주소 변환을 담당하는 하드웨어 부품. CPU에서 발생하는 가상 주소를 물리 주소로 변환해준다.

### TLB와 MMU는 어디에 위치해 있나요?

보통 CPU 내부에 위치한다. 이들은 CPU와 메모리 사이에서 주소 변환가 같은 작업을 처리한다.

## 21. 페이지 교체 알고리즘에 대해 설명해 주세요.

- **FIFO (first-in-first-out)** : 먼저 물리 메모리에 들어온 페이지 순서대로 페이지 교체 시점에 먼저 나간다.
  - 장점 : 이해하기 쉽고, 구현하기 쉽다.
  - 단편 : 오래된 페이지 여전히 활발하게 사용되고 있다면 비효율적일 수도 있다. 이를 Belady의 모순 현상이라고 부르며, 이는 FIFO 알고리즘이 메모리 크기가 증가함에 따라 페이지 부재율이 줄어들지 않는 현상을 말한다.
- **LRU (Least Recently Used)** : 가장 오래전에 참조된 페이지를 교체한다. 이는 프로그램의 지역성 원리에 근거한 것으로, **최근에 사용하지 않은 페이지는 앞으로도 사용할 가능성이 많다는 가정에 기반**한다. 이 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다.
  교체 알고리즘의 성능을 측정하기 위해서 (벤치마킹) 얘랑 가까울 수록 성능이 좋다.

- **OPR (Optimal Page REplacement)** : 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 것이다. 이 방법은 가장 낮은 페이지 부재율을 보장하지만, 이를 위해서는 미래의 페이지 참조를 미리 알아야 하므로 실제로는 구현이 불가능하다.

cf) Belady의 모순 현상을 일으키지 않는 알고리즘들을 스택 알고리즘이라고 한다.

### LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?

> **LRU (Least Recently Used)** : 가장 오래전에 참조된 페이지를 교체한다. 이는 프로그램의 지역성 원리에 근거한 것으로, **최근에 사용하지 않은 페이지는 앞으로도 사용할 가능성이 많다는 가정에 기반**한다. 이 정책은 페이지 교체 알고리즘으로 자주 사용되며 좋은 알고리즘으로 인정받고 있다.

### LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?

두 가지 방법이 가능하다.

1. **계수기 (counter)**

- 각 페이지 항목마다 사용 시간 필드를 넣고, CPU에 counter를 추가
- 메모리가 접근될 때마다 counter를 증가시킴
- 페이지에 대한 참조가 일어날 때 마다 페이지의 사용 시간 필드에 counter 내용이 복사됨. 이렇게 각 페이지의 마지막 참조 "시간"을 유지할 수 있음
- 페이지를 교체할 때, 시간 값이 가장 작은 페이지가 교체됨

이 방법은, LRU 페이지를 찾기 위해 페이지 테이블을 탐색해야하며 메모리 참조 시 때마다 페이지 테이블의 사용 시간 필드 갱신을 위해 쓰기 작업을 필요로 한다. 또한 시간 값을 계속 관리해야하고 (CPU 스케줄링에서도 발생할 수 있음) 시간 값의 overflow도 고려해야 한다.

2. **스택 (stack)**
   - 페이지 번호의 스택을 유지함
   - 페이지가 참조될 때마다 페이지 번호가 스택 중간에서 제거되어 스택의 top 에 놓이게 됨 (중간에서 원소를 지워야 하기 때문에 스택은 doubly linked list로 구현함)
   - 스택의 top은 가장 최근에 사용된 페이지이고, bottom은 가장 오랫동안 이용되지 않은 페이지임
